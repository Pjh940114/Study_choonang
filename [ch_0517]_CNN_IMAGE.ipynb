{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[ch_0517]_CNN_IMAGE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1f4pVzDdmMBJU0DyqxzrNzN7EP44DoeG8",
      "authorship_tag": "ABX9TyMAXaIwq/vF2WGD1G4kULoi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pjh940114/Study_choonang/blob/main/%5Bch_0517%5D_CNN_IMAGE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "vt0MAVgGnZwn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam # 평균적으로 높은 효율을 내는 알고리즘\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageDataGenerator 객체 생성\n",
        "Train_Datagen = ImageDataGenerator(rescale = 1/255)\n",
        "Test_Datagen = ImageDataGenerator(rescale = 1/255)"
      ],
      "metadata": {
        "id": "AA44Z-gWnttN"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/drive/MyDrive/cats_and_dogs_small/train\"\n",
        "test_dir = \"/content/drive/MyDrive/cats_and_dogs_small/test\""
      ],
      "metadata": {
        "id": "JPx1MBmKpmgk"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageDataGenerator 설정\n",
        "train_generator = Train_Datagen.flow_from_directory(\n",
        "    train_dir, # 학습용 이미지를 가져올 폴더\n",
        "    classes = ['cats', 'dogs'], # cat 폴더의 이미지 label 을 0으로, dogs 폴더의 이미지 label 을 1로 설정\n",
        "    target_size = (150, 150), # 이미지 resize\n",
        "    batch_size = 20, # 한번에 20개의 이미지만 가져와서 학습\n",
        "    class_mode = 'binary'  # 이진분류\n",
        ")\n",
        "\n",
        "# 평가용\n",
        "test_generator = Test_Datagen.flow_from_directory(\n",
        "    test_dir, # 평가용 이미지를 가져올 폴더\n",
        "    classes = ['cats', 'dogs'], # cat 폴더의 이미지 label 을 0으로, dogs 폴더의 이미지 label 을 1로 설정\n",
        "    target_size = (150, 150), # 이미지 resize\n",
        "    batch_size = 20, \n",
        "    class_mode = 'binary'  # 이진분류\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEbocafdoHLz",
        "outputId": "154ab2aa-9a56-4fea-c99c-fcc94845d1e0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model 구현\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32,\n",
        "                 kernel_size=(3,3),\n",
        "                 strides=(1,1),\n",
        "                 activation='relu',\n",
        "                 input_shape=(150,150,3)))\n",
        "\n",
        "model.add(Conv2D(filters=64,\n",
        "                 kernel_size=(3,3),\n",
        "                 strides=(1,1),\n",
        "                 activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=64,\n",
        "                 kernel_size=(3,3),\n",
        "                 strides=(1,1),\n",
        "                 activation='relu'))"
      ],
      "metadata": {
        "id": "vy8q9NxaqmwE"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FC layer(DNN)의 input layer\n",
        "model.add(Flatten())    # 전체 데이터를 4차원에서 2차원으로 변경\n",
        "\n",
        "# hidden layer\n",
        "model.add(Dense(units=256,\n",
        "                activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(units=1,\n",
        "                activation='sigmoid'))"
      ],
      "metadata": {
        "id": "StRyOw8wr_kz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(model.summary())\n",
        "# model이 어떻게 동작하는지를 지정\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ADolilOdtwE1"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 설정이 다 되었으면 모델을 학습.\n",
        "model.fit(train_generator,\n",
        "          steps_per_epoch=100,\n",
        "          epochs=30,\n",
        "          verbose=1,\n",
        "          validation_data=test_generator,\n",
        "          validation_steps=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMXP9MjXtyar",
        "outputId": "bdb737c4-0831-4731-c746-4d8157dddd3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 479s 5s/step - loss: 0.6916 - accuracy: 0.5680 - val_loss: 0.6934 - val_accuracy: 0.5430\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 289s 3s/step - loss: 0.5929 - accuracy: 0.6915 - val_loss: 0.6272 - val_accuracy: 0.6370\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 291s 3s/step - loss: 0.4671 - accuracy: 0.7815 - val_loss: 0.6547 - val_accuracy: 0.6250\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 291s 3s/step - loss: 0.3535 - accuracy: 0.8615 - val_loss: 0.7242 - val_accuracy: 0.6340\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 291s 3s/step - loss: 0.2432 - accuracy: 0.9185 - val_loss: 0.6728 - val_accuracy: 0.6860\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 291s 3s/step - loss: 0.1532 - accuracy: 0.9585 - val_loss: 0.8100 - val_accuracy: 0.6490\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 291s 3s/step - loss: 0.0976 - accuracy: 0.9805 - val_loss: 0.8809 - val_accuracy: 0.6790\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 292s 3s/step - loss: 0.0554 - accuracy: 0.9940 - val_loss: 0.9624 - val_accuracy: 0.6750\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 292s 3s/step - loss: 0.0341 - accuracy: 0.9975 - val_loss: 1.0432 - val_accuracy: 0.6700\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 292s 3s/step - loss: 0.0272 - accuracy: 0.9985 - val_loss: 1.1471 - val_accuracy: 0.6790\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 294s 3s/step - loss: 0.0134 - accuracy: 0.9995 - val_loss: 1.2334 - val_accuracy: 0.6670\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 295s 3s/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.3116 - val_accuracy: 0.6660\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 293s 3s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.3746 - val_accuracy: 0.6660\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 293s 3s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4326 - val_accuracy: 0.6610\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 294s 3s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5041 - val_accuracy: 0.6590\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 293s 3s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5252 - val_accuracy: 0.6660\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 293s 3s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5608 - val_accuracy: 0.6710\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 293s 3s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.5982 - val_accuracy: 0.6680\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 292s 3s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6384 - val_accuracy: 0.6660\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 292s 3s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6695 - val_accuracy: 0.6660\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - ETA: 0s - loss: 9.1499e-04 - accuracy: 1.0000"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_ygxo9WUvbWz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}